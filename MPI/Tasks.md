# MPI #

## Задачи ##

1. Hello world из всех процессов (2 балла)
2. Max вектора  (3 балла)
3. Вычисление числа Пи методом Монте-Карло (3 баллов)     
4. Среднее арифметическое среди положительных чисел массива (3 баллов) 
5. Скалярное произведение (3 балла)
6. Maxmin матрицы (5 балла)  
7. Умножение матрицы на вектор при разделении данных по столбцам (7 баллов)
8. Scatter и Gather через Send и Recv(6 баллов)
9. Инвертировать массив (6 баллов)  
10. Время передачи для разных Send-oв (6 баллов)
11. Передача чисел по кругу  для различных коммуникаторов(6 баллов)    
12. Проверка матрицы на симметричность (11 баллов)  
13. Сортировка массива методом чет-нечетной перестановки (13 баллов)
14. Умножение матриц алгоритм Кэннона  (13 баллов)
15. Сортировка данных методом Шелла (13 баллов)
16. Метод Гаусса (13 баллов)

### Спецификации задач ###

1. уметь запускать MPI
2. уметь использовать что-то из send, recv,  bcast, reduce
3. метод Монте-Карло для получения Пи, понимается как генерирование случайной последовательности точек из квадрата со сторонами 2 и центром в центре координат. Доля точек попавших в круг с радиусом один умноженная на 4 должна стремиться к числу Пи. Распараллеливание заключается в сбалансированном распределении итераций по процессам.
4. Распределение данных через scatterv.
5. Распределение данных через scatterv. Есть два массива. надо найти суммы произведений соответствующих координат.
6. найти седловую точку матрицы. Распределение данных через scatterv. Каждый процесс получает какое-то количество строк матрицы. Находит для каждой строки минимум и выбирает из  них максимальный. Далее из локальных максимумов выбирает глобальный.
7. На одном процессе заполняется матрица и вектор. Каждый процесс получает несколько столбцов матрицы и столько же элементов вектора. Высчитывает частичную сумму результирующего вектора.  ci = A i,j * b j   для  j-го столбца. Если столбцов несколько то cj суммируются. Далее все частичные суммы собираются в результат.
8. На одном процессе есть массив из n чисел. Выводим его. При помощи send, recv раздаем всем процессам по n/size чисел. Свою часть так же копируем в другой массив  размера n/size.  Выводим номер каждого процесса и его часть массива. Далее при помощи send, recv собираем все части массива на каком-либо процессе в новый массив размера n.  Выводим его.
9. Перевернуть массив. Работа процессов должна быть сбалансирована. Можно использовать как и Scatter, Gather, так и  Send, Recv.
10. Программу тестируем на двух процессах. Используем Send, Ssend, Bsend и Rsend . передаем какой-либо длинный массив или строку второму процессу, и получаем  обратно. Замеряем время потраченные на эти операции.
11. В коммуникаторе передаем сообщение от одного процесса другому с нулевого до size-1. Последний процесс отправляет сообщение нулевому. На каждом процессе сообщение изменяется, если это число, то можно прибавлять или умножать на что-то. После полного круга, создаем новый коммуникатор (произвольным образом ) и повторяем процедуру.
12. Задача не несёт никакой практической пользы от распараллеливания. Каждый процесс должен получить только нужные ему данные и работа процессов должна быть достаточно сбалансирована. 
13. 16 задачи есть в pdf файлах. Рассмотрим алгоритмы на ближайших занятиях.